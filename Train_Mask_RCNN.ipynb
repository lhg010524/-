{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "!git clone 'https://github.com/lhg010524/Detection_Abandoned-vehicle'\n",
        "dist = distutils.core.run_setup(\"./Detection_Abandoned-vehicle/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "import sys, os\n",
        "sys.path.insert(0, os.path.abspath('./Detection_Abandoned-vehicle/detectron2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf3eqcEHIheK",
        "outputId": "503c34d7-e12b-45fb-91ea-6717fff419ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 15819, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 15819 (delta 31), reused 43 (delta 17), pack-reused 15743 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15819/15819), 6.39 MiB | 1.05 MiB/s, done.\n",
            "Resolving deltas: 100% (11523/11523), done.\n",
            "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs>=0.1.8) (6.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.1)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=c3cee21c5bd54b087d1561204c0b865249c710968abdc673965b83d3f41e00ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=ac34e4f0a57b3c5377b034aefd8ffd85a4db468dc24c5998497e3cd49c65e4e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQvcJyXPIi1Q",
        "outputId": "26fcfa53-c5bc-4467-aec5-3c3eb6d78ea0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.5 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "bFASZPq_IkRx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import random\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from google.colab.patches import cv2_imshow\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# 어노테이션 파일 및 이미지 디렉토리 설정\n",
        "annotation_files = [\n",
        "    \"/content/detectron2/1024_1.json\",\n",
        "    \"/content/detectron2/1024_2.json\",\n",
        "    \"/content/detectron2/1024_ver2_1.json\",\n",
        "    \"/content/detectron2/1024_ver2_2.json\",\n",
        "    \"/content/detectron2/1024_ver2_3.json\",\n",
        "    \"/content/detectron2/1024_ver2_4.json\",\n",
        "    \"/content/detectron2/256.json\",\n",
        "    \"/content/detectron2/512.json\"\n",
        "]\n",
        "image_dir = \"/content/train\"\n",
        "\n",
        "# 모든 어노테이션 데이터를 병합\n",
        "def load_annotations(annotation_files):\n",
        "    merged_annotations = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
        "    annotation_id_offset = 0\n",
        "    image_id_offset = 0\n",
        "    image_id_map = {}\n",
        "\n",
        "    for anno_file in annotation_files:\n",
        "        with open(anno_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "            for img_data in data[\"images\"]:\n",
        "                new_image_id = image_id_offset + img_data[\"id\"]\n",
        "                image_id_map[img_data[\"id\"]] = new_image_id\n",
        "                img_data[\"id\"] = new_image_id\n",
        "                merged_annotations[\"images\"].append(img_data)\n",
        "            image_id_offset += len(data[\"images\"])\n",
        "\n",
        "            for anno_data in data[\"annotations\"]:\n",
        "                anno_data[\"id\"] = annotation_id_offset + anno_data[\"id\"]\n",
        "                anno_data[\"image_id\"] = image_id_map[anno_data[\"image_id\"]]\n",
        "                merged_annotations[\"annotations\"].append(anno_data)\n",
        "            annotation_id_offset += len(data[\"annotations\"])\n",
        "\n",
        "            if not merged_annotations[\"categories\"]:\n",
        "                merged_annotations[\"categories\"] = data[\"categories\"]\n",
        "\n",
        "    return merged_annotations\n",
        "\n",
        "# 이미지 파일 기준으로 어노테이션 데이터 필터링\n",
        "def filter_annotations_by_image(image_dir, annotations):\n",
        "    filtered_images = []\n",
        "    filtered_annotations = []\n",
        "    image_id_map = {}\n",
        "\n",
        "    for img_data in annotations[\"images\"]:\n",
        "        img_path = os.path.join(image_dir, img_data[\"file_name\"])\n",
        "        if os.path.exists(img_path):\n",
        "            filtered_images.append(img_data)\n",
        "            image_id_map[img_data[\"id\"]] = img_data\n",
        "\n",
        "    for anno_data in annotations[\"annotations\"]:\n",
        "        if anno_data[\"image_id\"] in image_id_map:\n",
        "            filtered_annotations.append(anno_data)\n",
        "\n",
        "    return {\n",
        "        \"images\": filtered_images,\n",
        "        \"annotations\": filtered_annotations,\n",
        "        \"categories\": annotations[\"categories\"],\n",
        "    }\n",
        "\n",
        "# 병합된 어노테이션 로드 및 필터링\n",
        "merged_annotations = load_annotations(annotation_files)\n",
        "filtered_data = filter_annotations_by_image(image_dir, merged_annotations)\n",
        "\n",
        "# 데이터를 학습 및 검증으로 분리\n",
        "def split_dataset(data, train_ratio=0.8):\n",
        "    images = data[\"images\"]\n",
        "    random.shuffle(images)\n",
        "    split_index = int(len(images) * train_ratio)\n",
        "    train_images = images[:split_index]\n",
        "    val_images = images[split_index:]\n",
        "\n",
        "    train_image_ids = {img[\"id\"] for img in train_images}\n",
        "    train_annotations = [anno for anno in data[\"annotations\"] if anno[\"image_id\"] in train_image_ids]\n",
        "    val_annotations = [anno for anno in data[\"annotations\"] if anno[\"image_id\"] not in train_image_ids]\n",
        "\n",
        "    train_data = {\n",
        "        \"images\": train_images,\n",
        "        \"annotations\": train_annotations,\n",
        "        \"categories\": data[\"categories\"],\n",
        "    }\n",
        "    val_data = {\n",
        "        \"images\": val_images,\n",
        "        \"annotations\": val_annotations,\n",
        "        \"categories\": data[\"categories\"],\n",
        "    }\n",
        "\n",
        "    return train_data, val_data\n",
        "\n",
        "train_data, val_data = split_dataset(filtered_data)\n",
        "\n",
        "# 분리된 데이터 저장\n",
        "train_annotation_path = \"/content/train_annotations.json\"\n",
        "val_annotation_path = \"/content/val_annotations.json\"\n",
        "with open(train_annotation_path, \"w\") as f:\n",
        "    json.dump(train_data, f)\n",
        "with open(val_annotation_path, \"w\") as f:\n",
        "    json.dump(val_data, f)\n",
        "\n",
        "# 데이터셋 등록\n",
        "train_dataset_name = \"vehicle_train\"\n",
        "val_dataset_name = \"vehicle_val\"\n",
        "register_coco_instances(train_dataset_name, {}, train_annotation_path, image_dir)\n",
        "register_coco_instances(val_dataset_name, {}, val_annotation_path, image_dir)\n",
        "\n",
        "# 메타데이터 및 데이터셋 정보 가져오기\n",
        "vehicle_train_metadata = MetadataCatalog.get(train_dataset_name)\n",
        "vehicle_val_metadata = MetadataCatalog.get(val_dataset_name)\n",
        "\n",
        "# 학습 데이터 시각화\n",
        "dataset_dicts = DatasetCatalog.get(train_dataset_name)\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=vehicle_train_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "# 학습 구성 객체 생성\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "\n",
        "# 데이터셋 설정\n",
        "cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
        "cfg.DATASETS.TEST = (val_dataset_name,)\n",
        "\n",
        "# 데이터 로더 설정\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "# 초기 가중치 설정\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "# 학습 하이퍼파라미터 설정\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "cfg.SOLVER.BASE_LR = 0.000125\n",
        "cfg.SOLVER.MAX_ITER = 6600         # 66\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 330  # 500 Iterations마다 체크포인트 저장\n",
        "\n",
        "# RoIHeads 설정\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "# 출력 디렉토리 설정\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# CustomTrainer 클래스 정의\n",
        "class CustomTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name):\n",
        "        return COCOEvaluator(dataset_name, output_dir=cfg.OUTPUT_DIR)\n",
        "\n",
        "# 평가 주기 설정\n",
        "cfg.TEST.EVAL_PERIOD = 330  # 원하는 평가 주기를 설정\n",
        "\n",
        "# 학습 시작\n",
        "trainer = CustomTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "PNWeOxh_IGX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import cv2\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# 테스트할 이미지 불러오기\n",
        "image_path = \"/(37.479637°, 126.636221°).png\"\n",
        "im = cv2.imread(image_path)\n",
        "\n",
        "# 이미지 제목에서 중심 위경도 추출\n",
        "match = re.search(r\"\\(([\\d.]+)°, ([\\d.]+)°\\)\", image_path)\n",
        "if match:\n",
        "    lat_center = float(match.group(1))\n",
        "    lon_center = float(match.group(2))\n",
        "else:\n",
        "    raise ValueError(\"이미지 제목에서 위경도를 추출할 수 없습니다.\")\n",
        "\n",
        "# 이미지 크기 및 실제 크기 정보\n",
        "image_size = 1024  # 1024x1024 픽셀\n",
        "real_size = 128  # 128x128 미터\n",
        "pixel_size = real_size / image_size  # 0.125m/pixel\n",
        "\n",
        "# 추론 수행\n",
        "outputs = predictor(im)\n",
        "\n",
        "# 바운딩 박스 중심 좌표 계산\n",
        "boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
        "centers = [(int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2)) for box in boxes]\n",
        "\n",
        "# 위도 및 경도 변환 계산\n",
        "lat_m_per_deg = 111320  # 위도 1도의 미터 단위\n",
        "lon_m_per_deg = 111320 * np.cos(np.radians(lat_center))  # 경도 1도의 미터 단위\n",
        "\n",
        "bounding_box_coords = []\n",
        "print(\"Bounding Box Coordinates with numbering (latitude, longitude):\")\n",
        "for idx, center in enumerate(centers):\n",
        "    pixel_dx = center[0] - image_size // 2  # 중심에서의 x 방향 픽셀 거리\n",
        "    pixel_dy = center[1] - image_size // 2  # 중심에서의 y 방향 픽셀 거리\n",
        "\n",
        "    # 실제 거리 변환\n",
        "    real_dx = pixel_dx * pixel_size  # x 방향 실제 거리 (미터)\n",
        "    real_dy = pixel_dy * pixel_size  # y 방향 실제 거리 (미터)\n",
        "\n",
        "    # 위도/경도로 변환\n",
        "    lat_offset = real_dy / lat_m_per_deg\n",
        "    lon_offset = real_dx / lon_m_per_deg\n",
        "\n",
        "    bbox_lat = lat_center + lat_offset\n",
        "    bbox_lon = lon_center + lon_offset\n",
        "\n",
        "    bounding_box_coords.append((bbox_lat, bbox_lon))\n",
        "    print(f\"Object {idx + 1}: Center at ({bbox_lat:.6f}, {bbox_lon:.6f})\")\n",
        "\n",
        "    # 이미지 위에 객체 넘버링 표시\n",
        "    cv2.putText(\n",
        "        im,\n",
        "        f\"{idx + 1}\",\n",
        "        (center[0], center[1]),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.5,  # 폰트 크기\n",
        "        (0, 255, 0),  # 색상 (초록)\n",
        "        2  # 두께\n",
        "    )\n",
        "\n",
        "# 출력 결과 시각화\n",
        "v = Visualizer(im[:, :, ::-1], metadata=vehicle_metadata, scale=0.5)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "# Colab에서 이미지를 표시\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "cv2_imshow(im)  # 넘버링된 원본 이미지 출력"
      ],
      "metadata": {
        "id": "MWnlvXMSITu2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}